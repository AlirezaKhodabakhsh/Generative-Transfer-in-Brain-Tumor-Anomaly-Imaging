{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.nn import init\n",
    "from torchvision.utils import make_grid\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalization(x):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : np.array : (H, W)\n",
    "\n",
    "    Return:\n",
    "        np.array : (H, W)\n",
    "    \"\"\"\n",
    "    x = x - x.min()\n",
    "    x = x / x.max()\n",
    "    x = x - 0.5\n",
    "    return  x / 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ploter(image, image_hat):\n",
    "    \"\"\"\n",
    "    (H, W)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image_hat, cmap='gray', vmin=-1, vmax=1)\n",
    "    #plt.imshow(image_hat)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Reconstruct\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(image, cmap='gray', vmin=-1, vmax=1)\n",
    "    #plt.imshow(image)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Anomaly_Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root\n",
    "                 ):\n",
    "        super(Anomaly_Dataset, self).__init__()\n",
    "\n",
    "        self.data = Anomaly_Dataset.load_dataset(root)\n",
    "        self.image, self.label = Anomaly_Dataset.get_numpy(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x, y =  self.image[item], self.label[item]\n",
    "\n",
    "        # RGB -> GRAY : (H, W)\n",
    "        x = x[:,:,0]\n",
    "\n",
    "        # (1, H, W)\n",
    "        x = Anomaly_Dataset.normalization(x)\n",
    "        #x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(path):\n",
    "        img_rows = 128\n",
    "        img_cols = 128\n",
    "        return image_dataset_from_directory(directory = path,\n",
    "                                               label_mode = 'int',\n",
    "                                               color_mode = 'rgb',\n",
    "                                               shuffle = False,\n",
    "                                               batch_size = None,\n",
    "                                               image_size = (img_rows, img_cols),\n",
    "                                               crop_to_aspect_ratio = True)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_numpy(PrefetchDataset):\n",
    "        \"\"\"\n",
    "        return:\n",
    "            (N, H, W, C) , (N,)\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        for (image, label) in PrefetchDataset:\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def rgb_2_gray(x):\n",
    "        \"\"\"\n",
    "        (H, W, C) --> (H, W)\n",
    "        \"\"\"\n",
    "        return cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalization(x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x : np.array : (H, W)\n",
    "\n",
    "        Return:\n",
    "            np.array : (H, W)\n",
    "        \"\"\"\n",
    "        x = x - x.min(keepdims=True)\n",
    "        x = x / x.max(keepdims=True)\n",
    "        x = x - 0.5\n",
    "        return  x / 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Net : It should be same as ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, init_features):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = Encoder._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = Encoder._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = Encoder._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = Encoder._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bottleneck = Encoder._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        return bottleneck, enc4, enc3, enc2, enc1\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, init_features, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = Decoder._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = Decoder._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = Decoder._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = Decoder._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, bottleneck, enc4, enc3, enc2, enc1):\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.tanh(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, init_features):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder = Encoder(in_channels, features)\n",
    "        self.decoder = Decoder(features, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.bottleneck, self.enc4, self.enc3, self.enc2, self.enc1 = self.encoder(x)\n",
    "        x_hat = self.decoder(self.bottleneck, self.enc4, self.enc3, self.enc2, self.enc1)\n",
    "        return x_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, c_dim , df_dim=32):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.fea1 = nn.Sequential(\n",
    "            SpectralNorm(nn.Conv2d(c_dim, df_dim, kernel_size=5, stride=2, padding=0)),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            SpectralNorm(nn.Conv2d(df_dim, df_dim*2, kernel_size=5, stride=2, padding=0)),\n",
    "            nn.BatchNorm2d(df_dim*2, 0.5), nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            SpectralNorm(nn.Conv2d(df_dim*2, df_dim*4, kernel_size=3, stride=2, padding=0)),\n",
    "            nn.BatchNorm2d(df_dim*4, 0.5), nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            SpectralNorm(nn.Conv2d(df_dim*4, df_dim*8, kernel_size=3, stride=2, padding=0)),\n",
    "            nn.BatchNorm2d(df_dim*8, 0.5), nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=6, stride=6))\n",
    "\n",
    "        self.concat = nn.Sequential(nn.Dropout(0.2), nn.Linear(256, 128),\n",
    "                                    nn.Dropout(0.2), nn.Linear(128, 1)\n",
    "                                )\n",
    "\n",
    "    def forward(self, img):\n",
    "        fea1_out = self.fea1(img).flatten(start_dim=1)\n",
    "        validity = self.concat(fea1_out)\n",
    "\n",
    "        return validity\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "lr_decoder = 0.5\n",
    "lr_y=0.001\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "# epochs\n",
    "epochs= 500\n",
    "disp_freq=20\n",
    "display_step=20\n",
    "\n",
    "step_bins = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best Generator and Criti\n",
    "c_dim , gf_dim = 1, 8\n",
    "df_dim = 32\n",
    "\n",
    "gen = Generator(c_dim, c_dim, gf_dim).to(device)\n",
    "crit = Critic(c_dim, df_dim).to(device)\n",
    "\n",
    "best_model = torch.load(\"epoch_969_loss_0.0065.pt\")\n",
    "\n",
    "gen.load_state_dict(best_model['Generator'])\n",
    "crit.load_state_dict(best_model['Critic'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Abnormal Tumar\n",
    "root = \"./../../dataset/kaggle1/tamiz\"\n",
    "dataset = Anomaly_Dataset(root)\n",
    "test_loader = DataLoader(dataset, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for image_test,_ in test_loader:\n",
    "    image_test = image_test.unsqueeze(1).to(device)\n",
    "    image_hat = gen(image_test)\n",
    "i=0\n",
    "plt.figure()\n",
    "ploter(image_test[i,0].detach().cpu(), image_hat[i,0].detach().cpu())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load best"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Respect to ibottleneck, enc4, enc3, enc2, enc1\n",
    "\"\"\"\n",
    "bottleneck, enc4, enc3, enc2, enc1 = gen.encoder(image_test)\n",
    "x_hat = gen.decoder(bottleneck, enc4, enc3, enc2, enc1)\n",
    "\n",
    "\n",
    "bottleneck = Parameter(bottleneck)\n",
    "enc4 = Parameter(enc4)\n",
    "enc3 = Parameter(enc3)\n",
    "enc2 = Parameter(enc2)\n",
    "enc1 = Parameter(enc1)\n",
    "\n",
    "\n",
    "gen.requires_grad_(False)\n",
    "crit.requires_grad_(False)\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "#optim_decoder = torch.optim.Adam([bottleneck], lr=lr_decoder, betas=(beta_1, beta_2))\n",
    "#optim_decoder = torch.optim.Adam([bottleneck])\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Respect to image_test (image_tomur)\n",
    "for image_test,_ in test_loader:\n",
    "    cur_batch_size = len(image_test)\n",
    "    image_test = image_test.unsqueeze(1).to(device)\n",
    "\n",
    "# optimizer\n",
    "y = Parameter(image_test.clone())\n",
    "optim_y = torch.optim.Adam([y], lr=lr_y, betas=(beta_1, beta_2))\n",
    "\n",
    "gen.requires_grad_(False)\n",
    "crit.requires_grad_(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train respect to y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "decoder_losses = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    print(60 * \"#\")\n",
    "    print(6 * \"#\" + \" Epoch \" + str(epoch) + \" \" + 45 * \"#\")\n",
    "    print(60 * \"#\")\n",
    "\n",
    "    # Set mode on \"train mode\"\n",
    "    gen.train()\n",
    "    crit.eval()\n",
    "\n",
    "    # Loss pixel\n",
    "    pixel_diff = nn.MSELoss()\n",
    "\n",
    "    # Decoder Star Learning\n",
    "    optim_y.zero_grad()\n",
    "    y_hat = gen(y)\n",
    "    y_loss = 10*( -crit(y_hat) ).mean(dim=0) + 5*pixel_diff(y, image_test)\n",
    "    y_loss.backward(retain_graph=True)\n",
    "    optim_y.step()\n",
    "    decoder_losses += [y_loss.item()]\n",
    "\n",
    "    ### Visualization code ###\n",
    "    if cur_step % display_step == 0 and cur_step > 0:\n",
    "        decoder_mean = sum(decoder_losses[-display_step:]) / display_step\n",
    "        print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {decoder_mean}\")\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        #i=0\n",
    "        ploter(image_test[i,0].detach().cpu(), y[i,0].detach().cpu())\n",
    "        plt.show()\n",
    "        diff = (normalization(y[0][0]) - image_test[0][0]).abs()\n",
    "        plt.imshow(diff.detach().cpu(), cmap='gray', vmin=0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        num_examples = (len(decoder_losses) // step_bins) * step_bins\n",
    "        plt.plot(\n",
    "            range(num_examples // step_bins),\n",
    "            torch.Tensor(decoder_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "            label=\"Decoder Loss\"\n",
    "        )\n",
    "        plt.show()\n",
    "    cur_step += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ploter(image_test[0][0].detach().cpu(), normalization(image_hat[0][0]).detach().cpu())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for epoch in range(1,epochs+1):\n",
    "    print(60 * \"#\")\n",
    "    print(6 * \"#\" + \" Epoch \" + str(epoch) + \" \" + 45 * \"#\")\n",
    "    print(60 * \"#\")\n",
    "\n",
    "    # Set mode on \"train mode\"\n",
    "    gen.train()\n",
    "    crit.eval()\n",
    "    for image_test,_ in test_loader:\n",
    "        cur_batch_size = len(image_test)\n",
    "\n",
    "        image_test = image_test.unsqueeze(1).to(device)\n",
    "\n",
    "        # Decoder Star Learning\n",
    "        optim_decoder.zero_grad()\n",
    "        image_hat = gen.decoder(bottleneck, enc4, enc3, enc2, enc1)\n",
    "        decoder_loss = ( -crit(image_hat) ).mean(dim=0)\n",
    "        decoder_loss.backward(retain_graph=True)\n",
    "        optim_decoder.step()\n",
    "        decoder_losses += [decoder_loss.item()]\n",
    "\n",
    "    ### Visualization code ###\n",
    "    if cur_step % display_step == 0 and cur_step > 0:\n",
    "        decoder_mean = sum(decoder_losses[-display_step:]) / display_step\n",
    "        print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {decoder_mean}\")\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        #i=0\n",
    "        #ploter(image_test[i,0].detach().cpu(), image_hat[i,0].detach().cpu())\n",
    "        #plt.show()\n",
    "        diff = (normalization(image_hat[0][0]) - image_test[0][0]).abs()\n",
    "        plt.imshow(diff.detach().cpu(), cmap='gray', vmin=0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        num_examples = (len(decoder_losses) // step_bins) * step_bins\n",
    "        plt.plot(\n",
    "            range(num_examples // step_bins),\n",
    "            torch.Tensor(decoder_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "            label=\"Decoder Loss\"\n",
    "        )\n",
    "        plt.show()\n",
    "    cur_step += 1\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### End"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ploter(image_test[0][0].detach().cpu(), normalization(image_hat[0][0]).detach().cpu())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}