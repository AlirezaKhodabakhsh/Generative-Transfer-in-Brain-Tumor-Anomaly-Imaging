{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.nn import init\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, init_features):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = Encoder._block(in_channels, features, name=\"enc1\")\n",
    "        self.encoder2 = Encoder._block(features, features * 2, name=\"enc2\")\n",
    "        self.encoder3 = Encoder._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.encoder4 = Encoder._block(features * 4, features * 8, name=\"enc4\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "        enc4 = self.encoder4(enc3)\n",
    "\n",
    "        return enc4, enc3, enc2, enc1\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                    (name + \"pooling\",nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'init_features'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6388/3036687168.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# TEST\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mC\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mH\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mW\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m200\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m200\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mencoder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEncoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mC\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mH\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mW\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mencoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'init_features'"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "N, C, H, W = 1, 3, 200, 200\n",
    "encoder = Encoder(3)\n",
    "x = torch.ones(N, C, H, W)\n",
    "encoder(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, init_features, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)\n",
    "        self.decoder4 = Decoder._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)\n",
    "        self.decoder3 = Decoder._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n",
    "        self.decoder2 = Decoder._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n",
    "        self.decoder1 = Decoder._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=features, out_channels=out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, bottleneck, enc4, enc3, enc2, enc1):\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# my unet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(MyUNet, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(in_channels, init_features)\n",
    "        self.bottleneck = MyUNet._block(init_features * 8, init_features * 16, name=\"bottleneck\")\n",
    "        self.decoder = Decoder(init_features, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        enc4, enc3, enc2, enc1 = self.encoder(x)\n",
    "        bottleneck = self.bottleneck(enc4)\n",
    "        x_hat = self.decoder(bottleneck, enc4, enc3, enc2, enc1)\n",
    "\n",
    "        return torch.sigmoid(self.conv(x_hat))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 32 but got size 16 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6388/1273812546.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mm\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMyUNet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mC\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mH\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mW\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6388/1318319997.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[0menc4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[0mbottleneck\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbottleneck\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0menc4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[0mx_hat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbottleneck\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msigmoid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_hat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6388/745167607.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, bottleneck, enc4, enc3, enc2, enc1)\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbottleneck\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m         \u001B[0mdec4\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupconv4\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbottleneck\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m         \u001B[0mdec4\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdec4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menc4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m         \u001B[0mdec4\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecoder4\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdec4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 32 but got size 16 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Test\n",
    "N, C, H, W = 10, 3, 256, 256\n",
    "m = MyUNet(3, 3)\n",
    "x = torch.ones(N, C, H, W)\n",
    "m(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nn.Linear"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'training': True,\n '_parameters': OrderedDict(),\n '_buffers': OrderedDict(),\n '_non_persistent_buffers_set': set(),\n '_backward_hooks': OrderedDict(),\n '_is_full_backward_hook': None,\n '_forward_hooks': OrderedDict(),\n '_forward_pre_hooks': OrderedDict(),\n '_state_dict_hooks': OrderedDict(),\n '_load_state_dict_pre_hooks': OrderedDict(),\n '_modules': OrderedDict([('encoder1',\n               Sequential(\n                 (enc1conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc1relu1): ReLU(inplace=True)\n                 (enc1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc1relu2): ReLU(inplace=True)\n               )),\n              ('pool1',\n               MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n              ('encoder2',\n               Sequential(\n                 (enc2conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc2relu1): ReLU(inplace=True)\n                 (enc2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc2relu2): ReLU(inplace=True)\n               )),\n              ('pool2',\n               MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n              ('encoder3',\n               Sequential(\n                 (enc3conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc3relu1): ReLU(inplace=True)\n                 (enc3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc3relu2): ReLU(inplace=True)\n               )),\n              ('pool3',\n               MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n              ('encoder4',\n               Sequential(\n                 (enc4conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc4relu1): ReLU(inplace=True)\n                 (enc4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (enc4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (enc4relu2): ReLU(inplace=True)\n               )),\n              ('pool4',\n               MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n              ('bottleneck',\n               Sequential(\n                 (bottleneckconv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (bottlenecknorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (bottleneckrelu1): ReLU(inplace=True)\n                 (bottleneckconv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (bottlenecknorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (bottleneckrelu2): ReLU(inplace=True)\n               )),\n              ('upconv4',\n               ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))),\n              ('decoder4',\n               Sequential(\n                 (dec4conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec4relu1): ReLU(inplace=True)\n                 (dec4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec4relu2): ReLU(inplace=True)\n               )),\n              ('upconv3',\n               ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))),\n              ('decoder3',\n               Sequential(\n                 (dec3conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec3relu1): ReLU(inplace=True)\n                 (dec3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec3relu2): ReLU(inplace=True)\n               )),\n              ('upconv2',\n               ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))),\n              ('decoder2',\n               Sequential(\n                 (dec2conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec2relu1): ReLU(inplace=True)\n                 (dec2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec2relu2): ReLU(inplace=True)\n               )),\n              ('upconv1',\n               ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))),\n              ('decoder1',\n               Sequential(\n                 (dec1conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec1relu1): ReLU(inplace=True)\n                 (dec1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                 (dec1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                 (dec1relu2): ReLU(inplace=True)\n               )),\n              ('conv', Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1)))])}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = UNet()\n",
    "m.__dict__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(MyLinear, self).__init__()\n",
    "        self.in_features = Parameter(torch.tensor(in_features).to(torch.float))\n",
    "        self.out_features = out_features\n",
    "        #self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        self.weight = torch.empty((out_features, in_features), **factory_kwargs)\n",
    "        if bias:\n",
    "            #self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "            self.bias = torch.empty(out_features, **factory_kwargs)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = Parameter(input).requires_grad_(False)\n",
    "        return F.linear(input, self.weight, self.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.9415, -0.9959,  0.2554, -0.2785,  0.8067,  0.1665, -0.1722,  0.3644,\n          0.2689, -0.1856,  0.8837,  0.1660, -0.1872, -0.0526,  0.5000,  0.1944,\n          0.3945, -0.1017, -0.7707,  0.5823]])"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MyLinear(10,20)\n",
    "x = torch.ones(1, 10).to(torch.float)\n",
    "m(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in m.parameters():\n",
    "    print(i.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# End UNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.empty(100, 3, 200, 200)\n",
    "A[:, 1, 100, 100].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Anomaly_Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root\n",
    "                 ):\n",
    "        super(Anomaly_Dataset, self).__init__()\n",
    "\n",
    "        self.data = Anomaly_Dataset.load_dataset(root)\n",
    "        self.image, self.label = Anomaly_Dataset.get_numpy(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x, y =  self.image[item], self.label[item]\n",
    "\n",
    "        # RGB -> GRAY : (H, W)\n",
    "        x = x[:,:,0]\n",
    "\n",
    "        # (1, H, W)\n",
    "        x = Anomaly_Dataset.normalization(x)\n",
    "        #x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(path):\n",
    "        img_rows = 135\n",
    "        img_cols = 135\n",
    "        return image_dataset_from_directory(directory = path,\n",
    "                                               label_mode = 'int',\n",
    "                                               color_mode = 'rgb',\n",
    "                                               shuffle = False,\n",
    "                                               batch_size = None,\n",
    "                                               image_size = (img_rows, img_cols),\n",
    "                                               crop_to_aspect_ratio = True)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_numpy(PrefetchDataset):\n",
    "        \"\"\"\n",
    "        return:\n",
    "            (N, H, W, C) , (N,)\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        for (image, label) in PrefetchDataset:\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def rgb_2_gray(x):\n",
    "        \"\"\"\n",
    "        (H, W, C) --> (H, W)\n",
    "        \"\"\"\n",
    "        return cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalization(x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x : np.array : (H, W)\n",
    "\n",
    "        Return:\n",
    "            np.array : (H, W)\n",
    "        \"\"\"\n",
    "        x = x - x.min(keepdims=True)\n",
    "        x = x / x.max(keepdims=True)\n",
    "        x = x - 0.5\n",
    "        return  x / 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_noise(num_z, z_dim, device='cpu'):\n",
    "    # mean, std = 0, 1\n",
    "    #return torch.empty(num_z, z_dim, 1, 1).normal_(mean, std).to(device)\n",
    "    return torch.randn(num_z, z_dim, 1, 1, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_noise(num_z, z_dim, device='cpu'):\n",
    "\n",
    "  steps_ = z_dim * (4*10**(-4))\n",
    "\n",
    "  sample_s = []\n",
    "  for _ in range(num_z):\n",
    "    sample = torch.normal(torch.arange(-0.5, 0.5, steps_), torch.arange(0,0.5,steps_/2)).unsqueeze(0)\n",
    "    sample_s += [sample]\n",
    "\n",
    "  return torch.concat(sample_s, dim=0).unsqueeze(-1).unsqueeze(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change activation to RELU\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim , c_dim , gf_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "        #                          output_padding=0,groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            Generator._block(z_dim, gf_dim*4, padding=0),\n",
    "            Generator._block(gf_dim*4, gf_dim*2),\n",
    "            Generator._block(gf_dim*2, gf_dim*1),\n",
    "            Generator._block(gf_dim*1, c_dim, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def forward(self,inp):\n",
    "        return self.gen(\n",
    "            inp\n",
    "        ) # (c_dim , 215 , 215 )\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, out_channels, kernel_size=5, stride=3, padding=1, final_layer=False):\n",
    "        if final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ELU(inplace = True)\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "gen = Generator(100, 1, 10)\n",
    "gen(get_noise(1, 100)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = self.encoder1(x)\n",
    "        self.z2 = self.encoder2(self.pool1(self.z1))\n",
    "        self.z3 = self.encoder3(self.pool2(self.z2))\n",
    "        self.z4 = self.encoder4(self.pool3(self.z3))\n",
    "\n",
    "        self.z5 = self.bottleneck(self.pool4(self.z4))\n",
    "\n",
    "        dec4 = self.upconv4(self.z5)\n",
    "        dec4 = torch.cat((dec4, self.z4), dim=1)\n",
    "\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, self.enc3), dim=1)\n",
    "\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, self.enc2), dim=1)\n",
    "\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, self.enc1), dim=1)\n",
    "\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = UNet._encoder_layer(in_channels , features * 1, name=\"enc1\")\n",
    "        self.encoder2 = UNet._encoder_layer(features * 1, features * 2, name=\"enc2\")\n",
    "        self.encoder3 = UNet._encoder_layer(features * 2, features * 4, name=\"enc3\")\n",
    "        self.encoder4 = UNet._encoder_layer(features * 4, features * 8, name=\"enc4\")\n",
    "\n",
    "        # important\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder4 = UNet._decoder_layer((features * 16) * 2, features * 8, name=\"dec4\")\n",
    "        self.decoder3 = UNet._decoder_layer((features *  8) * 2, features * 4, name=\"dec3\")\n",
    "        self.decoder2 = UNet._decoder_layer((features *  4) * 2, features * 2, name=\"dec2\")\n",
    "        self.decoder1 = UNet._decoder_layer((features *  2) * 2, features * 1, name=\"dec1\")\n",
    "\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.enc1 = self.encoder1(x)\n",
    "        self.enc2 = self.encoder2(self.enc1)\n",
    "        self.enc3 = self.encoder3(self.enc2)\n",
    "        self.enc4 = self.encoder4(self.enc3)\n",
    "\n",
    "        self.z5 = self.bottleneck(self.pool4(self.z4))\n",
    "\n",
    "        dec4 = self.upconv4(self.z5)\n",
    "        dec4 = torch.cat((dec4, self.z4), dim=1)\n",
    "\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, self.z3), dim=1)\n",
    "\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, self.z2), dim=1)\n",
    "\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, self.z1), dim=1)\n",
    "\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _encoder_layer(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + 'maxpool', nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _decoder_layer(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"upconv\", nn.ConvTranspose2d(in_channels, features, kernel_size=2, stride=2)\n",
    "                    ),\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=2*features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True))\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=10, out_features=20, bias=True)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ('fc1', nn.Linear(10,20)),\n",
    "        ('fc2', nn.Linear(20,30)),\n",
    "    ])\n",
    ")\n",
    "m.fc1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change activation to RELU\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self , c_dim , df_dim):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        # torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "        #                          output_padding=0,groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            Critic._block(c_dim, df_dim),\n",
    "            Critic._block(df_dim, df_dim*2),\n",
    "            Critic._block(df_dim*2, df_dim*4),\n",
    "            Critic._block(df_dim*4, 1, padding=0, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def forward(self,inp):\n",
    "        return self.critic(\n",
    "            inp\n",
    "        ).flatten(1) # (N , 1 , 1, 1 )\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, out_channels, kernel_size=5, stride=3, padding=1, final_layer=False):\n",
    "        if final_layer:\n",
    "            return nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ELU(inplace = True)\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "N, C, H, W = 10, 1, 135, 135\n",
    "x = torch.ones(N, C, H, W)\n",
    "dis = Critic(C, 10)\n",
    "dis(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_epsilon(N_epsilon, device='cpu'):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        N_epsilon : Number of epsilons\n",
    "    Output:\n",
    "        e.g. shape : (128, 1, 1, 1)\n",
    "    \"\"\"\n",
    "    return torch.rand(N_epsilon, 1, 1, 1, device=device, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_gradient(crit, data):\n",
    "    \"\"\"\n",
    "    Return the gradient of the critic's scores with respect to mixes of real and fake images.\n",
    "    Parameters:\n",
    "        dis: the critic model\n",
    "        data: a batch of data\n",
    "    Returns:\n",
    "        gradient: the gradient of the discriminator's scores, with respect to data\n",
    "    \"\"\"\n",
    "\n",
    "    # True require_grad of Data\n",
    "    data.requires_grad_()\n",
    "    # Calculate the discriminator's scores on the data\n",
    "    score = crit(data)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the data\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=data,\n",
    "        outputs=score,\n",
    "        # These other parameters have to do with the pytorch autograd engine works\n",
    "        grad_outputs=torch.ones_like(score),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    '''\n",
    "    Return the gradient penalty, given a gradient.\n",
    "    Given a batch of data gradients, you calculate the magnitude of each data's gradient\n",
    "    and penalize the mean quadratic distance of each magnitude to 1.\n",
    "\n",
    "    Parameters:\n",
    "        gradient: the gradient of the discriminator's scores, with respect to the data\n",
    "        e.g shape  : (128, 1, 28, 28)\n",
    "\n",
    "    Returns:\n",
    "        penalty: the gradient penalty\n",
    "        e.g shaoe : (scaler)\n",
    "    '''\n",
    "\n",
    "    # Flatten the gradients so that each row captures one image\n",
    "    # e.g shape  : (128, 1, 28, 28) ==> (128, 784)\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    # Calculate the magnitude of every row\n",
    "    # e.g shape : (128, 784) ==> (128, 1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "\n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    # e.g shape : (128, 1) ==> (scaler)\n",
    "    penalty = ( ( gradient_norm - 1.0 )**2 ).mean(dim=0)\n",
    "    return penalty"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_crit_loss(\n",
    "    image, z_dim,\n",
    "    gen, crit,\n",
    "    c_lambda,\n",
    "    device):\n",
    "    '''\n",
    "    Parameters:\n",
    "        All as same as DCGAN Losses\n",
    "    Returns:\n",
    "        dis_loss: a scalar for the dis's loss\n",
    "    '''\n",
    "    #x_no_tumor_fake = gen(x_tumor #+ get_noise(x_tumor, device=device)).detach()\n",
    "\n",
    "    image_hat = gen(\n",
    "        get_noise(image.shape[0], z_dim, device=device)\n",
    "    ).detach()\n",
    "\n",
    "    # Mixed \"real\" with \"fake\"\n",
    "    #epsilon = get_epsilon(N_epsilon = x_no_tumor.shape[0], device=device)\n",
    "    epsilon = get_epsilon(N_epsilon = image.shape[0], device=device)\n",
    "\n",
    "    #mixed_images = x_no_tumor * epsilon + x_no_tumor_fake * (1 - epsilon)\n",
    "    mixed_images = image * epsilon + image_hat * (1 - epsilon)\n",
    "\n",
    "    # Calculate Gradient Penalty (use prior funcs)\n",
    "    gp = gradient_penalty(get_gradient(crit, mixed_images))\n",
    "    # Calculate \"Line 7\" of \"Algorithm 1\" in main paper\n",
    "    #return ( dis(x_no_tumor_fake) - dis(x_no_tumor) + c_lambda * gp ).mean(dim=0)\n",
    "    return ( crit(image_hat) - crit(image) + c_lambda * gp ).mean(dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_gen_loss(\n",
    "      image,z_dim,\n",
    "      gen, crit,\n",
    "      device):\n",
    "    '''\n",
    "    Return the loss of a generator.\n",
    "    Parameters:\n",
    "\n",
    "    Returns:\n",
    "       a scalar loss value for the current batch of the generator\n",
    "    '''\n",
    "    image_hat = gen(\n",
    "        get_noise(image.shape[0], z_dim, device=device)\n",
    "    )\n",
    "    # Calculate \"Line 12\" of \"Algorithm 1\" in main paper\n",
    "    return ( -crit(image_hat) ).mean(dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ploter(image, image_hat):\n",
    "    \"\"\"\n",
    "    (H, W)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    #plt.imshow(image_hat, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.imshow(image_hat)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Reconstruct\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    #plt.imshow(image, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weights_init(submodules):\n",
    "    if isinstance(submodules, nn.Conv2d) or isinstance(submodules, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(submodules.weight, 0.0, 0.02)\n",
    "    if isinstance(submodules, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(submodules.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(submodules.bias, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 128, 128)):\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze(), cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparamters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_dim , c_dim , gf_dim = 100, 1, 64\n",
    "df_dim = 64\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "batch_size =20\n",
    "\n",
    "\n",
    "lr_gen, lr_crit = 0.002, 0.002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "# epochs\n",
    "epochs= 300\n",
    "disp_freq=1\n",
    "display_step=5\n",
    "\n",
    "crit_repeats=5\n",
    "c_lambda = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen = Generator(z_dim , c_dim , gf_dim).to(device)\n",
    "crit = Critic(c_dim, df_dim).to(device)\n",
    "\n",
    "# Initialize\n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)\n",
    "\n",
    "# Loss function\n",
    "#criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizers\n",
    "optim_crit = torch.optim.Adam(crit.parameters(), lr=lr_crit, betas=(beta_1, beta_2))\n",
    "optim_gen = torch.optim.Adam(gen.parameters(), lr=lr_gen, betas=(beta_1, beta_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root = \"./../dataset/kaggle1/no\"\n",
    "dataset = Anomaly_Dataset(root)\n",
    "dataloader_normal = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, y in dataloader_normal:\n",
    "    x=x\n",
    "    y=y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_noise(100,100).dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x[0], cmap='gray', vmin=-1, vmax=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "generator_losses = []\n",
    "critic_losses = []\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    print(60 * \"#\")\n",
    "    print(6 * \"#\" + \" Epoch \" + str(epoch) + \" \" + 45 * \"#\")\n",
    "    print(60 * \"#\")\n",
    "\n",
    "    # Set mode on \"train mode\"\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "\n",
    "    for image,_ in dataloader_normal:\n",
    "        cur_batch_size = len(image)\n",
    "        # GPU (model and data)\n",
    "        image = image.unsqueeze(1).to(device)\n",
    "\n",
    "        # Discriminator Learning\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "          optim_crit.zero_grad()\n",
    "          crit_loss  = get_crit_loss(image, z_dim, gen, crit, c_lambda, device=device)\n",
    "          crit_loss .backward(retain_graph=True)\n",
    "          optim_crit.step()\n",
    "          mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "        critic_losses += [mean_iteration_critic_loss]\n",
    "\n",
    "        # Generator Learning\n",
    "        optim_gen.zero_grad()\n",
    "        gen_loss  = get_gen_loss(image, z_dim, gen, crit, device=device)\n",
    "        gen_loss .backward()\n",
    "        optim_gen.step()\n",
    "        generator_losses += [gen_loss .item()]\n",
    "\n",
    "    # Save parameters of discriminator and generator\n",
    "    #save_model(gen, dis, epoch, root_models, mode='colab')\n",
    "    #print(\"Loss Dis: {:.2f}\\tLoss Gen: {:.2f}\".format(loss_dis,loss_gen))\n",
    "\n",
    "    ### Visualization code ###\n",
    "    if cur_step % display_step == 0 and cur_step > 0:\n",
    "        gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "        crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "        print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "\n",
    "\n",
    "\n",
    "        fake = gen(\n",
    "            get_noise(image.shape[0], z_dim, device)\n",
    "        )\n",
    "\n",
    "        #show_tensor_images(fake)\n",
    "        #show_tensor_images(image)\n",
    "\n",
    "        i=math.floor(np.random.uniform(0, image.shape[0]))\n",
    "        plt.figure()\n",
    "        ploter(image[i,0].detach().cpu(), fake[i,0].detach().cpu())\n",
    "        plt.show()\n",
    "\n",
    "        step_bins = 20\n",
    "        num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "        plt.plot(\n",
    "            range(num_examples // step_bins),\n",
    "            torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "            label=\"Generator Loss\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            range(num_examples // step_bins),\n",
    "            torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "            label=\"Critic Loss\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    cur_step += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root = \"./../dataset/kaggle1/no\"\n",
    "dataset = Anomaly_Dataset(root)\n",
    "dataloader_normal = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, y in dataloader_normal:\n",
    "    x=x\n",
    "    y=y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x[0], cmap='gray', vmin=-1, vmax=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}