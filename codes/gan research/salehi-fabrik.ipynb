{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import CelebA\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.nn import init\n",
    "from torchvision.utils import make_grid\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from skimage import transform\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import vgg16\n",
    "from pathlib import Path\n",
    "from torch.autograd import Variable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model\n",
    "    '''\n",
    "\n",
    "    def __init__(self, features):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "\n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "        self.activation = None\n",
    "\n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x, target_layer=11):\n",
    "        result = []\n",
    "        for i in range(len(nn.ModuleList(self.features))):\n",
    "            x = self.features[i](x)\n",
    "            if i == target_layer:\n",
    "                self.activation = x\n",
    "                h = x.register_hook(self.activations_hook)\n",
    "            if i == 2 or i == 5 or i == 8 or i == 11 or i == 14 or i == 17 or i == 20 or i == 23 or i == 26 or i == 29 or i == 32 or i == 35 or i == 38:\n",
    "                result.append(x)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def get_activations(self, x):\n",
    "        return self.activation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Vgg16(torch.nn.Module):\n",
    "    def __init__(self, pretrain):\n",
    "        super(Vgg16, self).__init__()\n",
    "        features = list(vgg16('vgg16-397923af.pth').features)\n",
    "\n",
    "        if not pretrain:\n",
    "            for ind, f in enumerate(features):\n",
    "                # nn.init.xavier_normal_(f)\n",
    "                if type(f) is torch.nn.modules.conv.Conv2d:\n",
    "                    torch.nn.init.xavier_uniform(f.weight)\n",
    "                    print(\"Initialized\", ind, f)\n",
    "                else:\n",
    "                    print(\"Bypassed\", ind, f)\n",
    "            # print(\"Pre-trained Network loaded\")\n",
    "        self.features = nn.ModuleList(features).eval()\n",
    "        self.output = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        for i in range(31):\n",
    "            x = self.features[i](x)\n",
    "            if i == 1 or i == 4 or i == 6 or i == 9 or i == 11 or i == 13 or i == 16 or i == 18 or i == 20 or i == 23 or i == 25 or i == 27 or i == 30:\n",
    "                output.append(x)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def make_layers(cfg, use_bias, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    outputs = []\n",
    "    for i in range(len(cfg)):\n",
    "        if cfg[i] == 'O':\n",
    "            outputs.append(nn.Sequential(*layers))\n",
    "        elif cfg[i] == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, cfg[i], kernel_size=3, padding=1, bias=use_bias)\n",
    "            torch.nn.init.xavier_uniform_(conv2d.weight)\n",
    "            if batch_norm and cfg[i + 1] != 'M':\n",
    "                layers += [conv2d, nn.BatchNorm2d(cfg[i]), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = cfg[i]\n",
    "    return nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def make_arch(idx, cfg, use_bias, batch_norm=False):\n",
    "    return VGG(make_layers(cfg[idx], use_bias, batch_norm=batch_norm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_networks(config, load_checkpoint=False):\n",
    "    equal_network_size = config['equal_network_size']\n",
    "    pretrain = config['pretrain']\n",
    "    experiment_name = config['experiment_name']\n",
    "    dataset_name = config['dataset_name']\n",
    "    normal_class = config['normal_class']\n",
    "    use_bias = config['use_bias']\n",
    "    cfg = {\n",
    "        'A': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "        'B': [16, 16, 'M', 16, 128, 'M', 16, 16, 256, 'M', 16, 16, 512, 'M', 16, 16, 512, 'M'],\n",
    "    }\n",
    "\n",
    "    if equal_network_size:\n",
    "        config_type = 'A'\n",
    "    else:\n",
    "        config_type = 'B'\n",
    "\n",
    "    vgg = Vgg16(pretrain).cuda()\n",
    "    model = make_arch(config_type, cfg, use_bias, True).cuda()\n",
    "\n",
    "    for j, item in enumerate(nn.ModuleList(model.features)):\n",
    "        print('layer : {} {}'.format(j, item))\n",
    "\n",
    "    if load_checkpoint:\n",
    "        last_checkpoint = config['last_checkpoint']\n",
    "        checkpoint_path = \"./outputs/{}/{}/checkpoints/\".format(experiment_name, dataset_name)\n",
    "        model.load_state_dict(\n",
    "            torch.load('{}Cloner_{}_epoch_{}.pth'.format(checkpoint_path, normal_class, last_checkpoint)))\n",
    "        if not pretrain:\n",
    "            vgg.load_state_dict(\n",
    "                torch.load('{}Source_{}_random_vgg.pth'.format(checkpoint_path, normal_class)))\n",
    "    elif not pretrain:\n",
    "        checkpoint_path = \"./outputs/{}/{}/checkpoints/\".format(experiment_name, dataset_name)\n",
    "        Path(checkpoint_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        torch.save(vgg.state_dict(), '{}Source_{}_random_vgg.pth'.format(checkpoint_path, normal_class))\n",
    "        print(\"Source Checkpoint saved!\")\n",
    "\n",
    "    return vgg, model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# hyper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "root_save = \"./best_models\"\n",
    "root_ds = \"./MNIST\"\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "batch_size = 64\n",
    "img_size = 32\n",
    "latent_dim = 100\n",
    "channels = 1\n",
    "num_epochs = 1000\n",
    "sample_interval = 1\n",
    "lr = 0.002\n",
    "n_critic = 5\n",
    "lambda_gp =10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "trans=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((0.5,) , (0.5,))\n",
    "])\n",
    "\n",
    "train_data=datasets.MNIST(root=root_ds,\n",
    "                          train=True, transform=trans, download=True)\n",
    "test_data=datasets.MNIST(root=root_ds,\n",
    "                          train=False, transform=trans, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_index(class_num, dataset, mode:str):\n",
    "    if mode == 'train':\n",
    "        class_indx = torch.nonzero(\n",
    "                dataset.train_labels == class_num * torch.ones_like(dataset.train_labels)\n",
    "        )\n",
    "\n",
    "    if mode == 'test':\n",
    "        class_indx = torch.nonzero(\n",
    "                dataset.test_labels == class_num * torch.ones_like(dataset.test_labels)\n",
    "        )\n",
    "\n",
    "    class_indx = class_indx.squeeze(1)\n",
    "    return class_indx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(get_index(8, train_data, 'train'))\n",
    "test_sampler = SubsetRandomSampler(get_index(8, test_data, 'test'))\n",
    "\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, sampler=train_sampler)\n",
    "test_loader=DataLoader(test_data, batch_size= len(test_sampler), sampler=test_sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class DirectionOnlyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DirectionOnlyLoss, self).__init__()\n",
    "        self.similarity_loss = torch.nn.CosineSimilarity()\n",
    "\n",
    "    def forward(self, output_pred, output_real):\n",
    "        y_pred_0, y_pred_1, y_pred_2, y_pred_3 = output_pred[3], output_pred[6], output_pred[9], output_pred[12]\n",
    "        y_0, y_1, y_2, y_3 = output_real[3], output_real[6], output_real[9], output_real[12]\n",
    "\n",
    "        loss_0 = torch.mean(1 - self.similarity_loss(y_pred_0.view(y_pred_0.shape[0], -1), y_0.view(y_0.shape[0], -1)))\n",
    "        loss_1 = torch.mean(1 - self.similarity_loss(y_pred_1.view(y_pred_1.shape[0], -1), y_1.view(y_1.shape[0], -1)))\n",
    "        loss_2 = torch.mean(1 - self.similarity_loss(y_pred_2.view(y_pred_2.shape[0], -1), y_2.view(y_2.shape[0], -1)))\n",
    "        loss_3 = torch.mean(1 - self.similarity_loss(y_pred_3.view(y_pred_3.shape[0], -1), y_3.view(y_3.shape[0], -1)))\n",
    "\n",
    "        total_loss = loss_0 + loss_1 + loss_2 + loss_3\n",
    "\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class MseDirectionLoss(nn.Module):\n",
    "    def __init__(self, lamda):\n",
    "        super(MseDirectionLoss, self).__init__()\n",
    "        self.lamda = lamda\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.similarity_loss = torch.nn.CosineSimilarity()\n",
    "\n",
    "    def forward(self, output_pred, output_real):\n",
    "        y_pred_0, y_pred_1, y_pred_2, y_pred_3 = output_pred[3], output_pred[6], output_pred[9], output_pred[12]\n",
    "        y_0, y_1, y_2, y_3 = output_real[3], output_real[6], output_real[9], output_real[12]\n",
    "\n",
    "        # different terms of loss\n",
    "        abs_loss_0 = self.criterion(y_pred_0, y_0)\n",
    "        loss_0 = torch.mean(1 - self.similarity_loss(y_pred_0.view(y_pred_0.shape[0], -1), y_0.view(y_0.shape[0], -1)))\n",
    "        abs_loss_1 = self.criterion(y_pred_1, y_1)\n",
    "        loss_1 = torch.mean(1 - self.similarity_loss(y_pred_1.view(y_pred_1.shape[0], -1), y_1.view(y_1.shape[0], -1)))\n",
    "        abs_loss_2 = self.criterion(y_pred_2, y_2)\n",
    "        loss_2 = torch.mean(1 - self.similarity_loss(y_pred_2.view(y_pred_2.shape[0], -1), y_2.view(y_2.shape[0], -1)))\n",
    "        abs_loss_3 = self.criterion(y_pred_3, y_3)\n",
    "        loss_3 = torch.mean(1 - self.similarity_loss(y_pred_3.view(y_pred_3.shape[0], -1), y_3.view(y_3.shape[0], -1)))\n",
    "\n",
    "        total_loss = loss_0 + loss_1 + loss_2 + loss_3 + self.lamda * (\n",
    "                abs_loss_0 + abs_loss_1 + abs_loss_2 + abs_loss_3)\n",
    "\n",
    "        return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "config = {'equal_network_size':False,\n",
    "'pretrain':True,\n",
    "'experiment_name':'local_equal_net',\n",
    "'dataset_name':'mnist',\n",
    "'normal_class':1,\n",
    "'use_bias':False,\n",
    "'equal_network_size':False}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer : 0 Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 1 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 2 ReLU(inplace=True)\n",
      "layer : 3 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 4 ReLU(inplace=True)\n",
      "layer : 5 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 6 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 7 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 8 ReLU(inplace=True)\n",
      "layer : 9 Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 10 ReLU(inplace=True)\n",
      "layer : 11 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 12 Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 13 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 14 ReLU(inplace=True)\n",
      "layer : 15 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 16 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 17 ReLU(inplace=True)\n",
      "layer : 18 Conv2d(16, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 19 ReLU(inplace=True)\n",
      "layer : 20 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 21 Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 22 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 23 ReLU(inplace=True)\n",
      "layer : 24 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 25 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 26 ReLU(inplace=True)\n",
      "layer : 27 Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 28 ReLU(inplace=True)\n",
      "layer : 29 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 30 Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 31 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 32 ReLU(inplace=True)\n",
      "layer : 33 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 34 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 35 ReLU(inplace=True)\n",
      "layer : 36 Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 37 ReLU(inplace=True)\n",
      "layer : 38 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "continue_train = False\n",
    "os.environ['TORCH_HOME'] = './pretrain_models'\n",
    "if continue_train:\n",
    "    vgg, model = get_networks(config, load_checkpoint=True)\n",
    "else:\n",
    "    vgg, model = get_networks(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Criteria And Optimizers\n",
    "direction_loss_only = False\n",
    "lamda = 0.01\n",
    "\n",
    "if direction_loss_only:\n",
    "    criterion = DirectionOnlyLoss()\n",
    "else:\n",
    "    criterion = MseDirectionLoss(lamda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/1000], loss:98.5623\n",
      "epoch [2/1000], loss:81.0720\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17328/2015299216.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m             \u001B[1;31m# Add loss to the list\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m             \u001B[0mepoch_loss\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mtotal_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m             \u001B[0mlosses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtotal_loss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(num_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for data in train_loader:\n",
    "            X = data[0]\n",
    "            if X.shape[1] == 1:\n",
    "                X = X.repeat(1, 3, 1, 1)\n",
    "            X = Variable(X).cuda()\n",
    "\n",
    "            output_pred = model.forward(X)\n",
    "            output_real = vgg(X)\n",
    "\n",
    "            total_loss = criterion(output_pred, output_real)\n",
    "\n",
    "            # Add loss to the list\n",
    "            epoch_loss += total_loss.item()\n",
    "            losses.append(total_loss.item())\n",
    "\n",
    "            # Clear the previous gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Compute gradients\n",
    "            total_loss.backward()\n",
    "            # Adjust weights\n",
    "            optimizer.step()\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, epoch_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(X)[12].flatten(1).mean(1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "343984"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        ...,\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]]], device='cuda:0')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}