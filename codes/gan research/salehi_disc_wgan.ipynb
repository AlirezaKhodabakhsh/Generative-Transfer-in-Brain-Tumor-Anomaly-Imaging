{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import CelebA\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.nn import init\n",
    "from torchvision.utils import make_grid\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from skimage import transform\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import vgg16\n",
    "from pathlib import Path\n",
    "from torch.autograd import Variable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model\n",
    "    '''\n",
    "\n",
    "    def __init__(self, features):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "\n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "        self.activation = None\n",
    "\n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x, target_layer=11):\n",
    "        result = []\n",
    "        for i in range(len(nn.ModuleList(self.features))):\n",
    "            x = self.features[i](x)\n",
    "            if i == target_layer:\n",
    "                self.activation = x\n",
    "                h = x.register_hook(self.activations_hook)\n",
    "            if i == 2 or i == 5 or i == 8 or i == 11 or i == 14 or i == 17 or i == 20 or i == 23 or i == 26 or i == 29 or i == 32 or i == 35 or i == 38:\n",
    "                result.append(x)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def get_activations(self, x):\n",
    "        return self.activation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Vgg16(torch.nn.Module):\n",
    "    def __init__(self, pretrain):\n",
    "        super(Vgg16, self).__init__()\n",
    "        features = list(vgg16('vgg16-397923af.pth').features)\n",
    "\n",
    "        if not pretrain:\n",
    "            for ind, f in enumerate(features):\n",
    "                # nn.init.xavier_normal_(f)\n",
    "                if type(f) is torch.nn.modules.conv.Conv2d:\n",
    "                    torch.nn.init.xavier_uniform(f.weight)\n",
    "                    print(\"Initialized\", ind, f)\n",
    "                else:\n",
    "                    print(\"Bypassed\", ind, f)\n",
    "            # print(\"Pre-trained Network loaded\")\n",
    "        self.features = nn.ModuleList(features).eval()\n",
    "        self.output = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        for i in range(31):\n",
    "            x = self.features[i](x)\n",
    "            if i == 1 or i == 4 or i == 6 or i == 9 or i == 11 or i == 13 or i == 16 or i == 18 or i == 20 or i == 23 or i == 25 or i == 27 or i == 30:\n",
    "                output.append(x)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def make_layers(cfg, use_bias, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    outputs = []\n",
    "    for i in range(len(cfg)):\n",
    "        if cfg[i] == 'O':\n",
    "            outputs.append(nn.Sequential(*layers))\n",
    "        elif cfg[i] == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, cfg[i], kernel_size=3, padding=1, bias=use_bias)\n",
    "            torch.nn.init.xavier_uniform_(conv2d.weight)\n",
    "            if batch_norm and cfg[i + 1] != 'M':\n",
    "                layers += [conv2d, nn.BatchNorm2d(cfg[i]), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = cfg[i]\n",
    "    return nn.Sequential(*layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def make_arch(idx, cfg, use_bias, batch_norm=False):\n",
    "    return VGG(make_layers(cfg[idx], use_bias, batch_norm=batch_norm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_networks(config, load_checkpoint=False):\n",
    "    equal_network_size = config['equal_network_size']\n",
    "    pretrain = config['pretrain']\n",
    "    experiment_name = config['experiment_name']\n",
    "    dataset_name = config['dataset_name']\n",
    "    normal_class = config['normal_class']\n",
    "    use_bias = config['use_bias']\n",
    "    cfg = {\n",
    "        'A': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "        'B': [16, 16, 'M', 16, 128, 'M', 16, 16, 256, 'M', 16, 16, 512, 'M', 16, 16, 512, 'M'],\n",
    "    }\n",
    "\n",
    "    if equal_network_size:\n",
    "        config_type = 'A'\n",
    "    else:\n",
    "        config_type = 'B'\n",
    "\n",
    "    vgg = Vgg16(pretrain).cuda()\n",
    "    model = make_arch(config_type, cfg, use_bias, True).cuda()\n",
    "\n",
    "    for j, item in enumerate(nn.ModuleList(model.features)):\n",
    "        print('layer : {} {}'.format(j, item))\n",
    "\n",
    "    if load_checkpoint:\n",
    "        last_checkpoint = config['last_checkpoint']\n",
    "        checkpoint_path = \"./outputs/{}/{}/checkpoints/\".format(experiment_name, dataset_name)\n",
    "        model.load_state_dict(\n",
    "            torch.load('{}Cloner_{}_epoch_{}.pth'.format(checkpoint_path, normal_class, last_checkpoint)))\n",
    "        if not pretrain:\n",
    "            vgg.load_state_dict(\n",
    "                torch.load('{}Source_{}_random_vgg.pth'.format(checkpoint_path, normal_class)))\n",
    "    elif not pretrain:\n",
    "        checkpoint_path = \"./outputs/{}/{}/checkpoints/\".format(experiment_name, dataset_name)\n",
    "        Path(checkpoint_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        torch.save(vgg.state_dict(), '{}Source_{}_random_vgg.pth'.format(checkpoint_path, normal_class))\n",
    "        print(\"Source Checkpoint saved!\")\n",
    "\n",
    "    return vgg, model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 512, 1, 1])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)[-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# hyper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "root_save = \"./best_models\"\n",
    "root_ds = \"./MNIST\"\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "batch_size = 64\n",
    "img_size = 32\n",
    "latent_dim = 100\n",
    "channels = 1\n",
    "num_epochs = 1000\n",
    "sample_interval = 1\n",
    "lr = 0.002\n",
    "n_critic = 5\n",
    "lambda_gp =10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "trans=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((0.5,) , (0.5,))\n",
    "])\n",
    "\n",
    "train_data=datasets.MNIST(root=root_ds,\n",
    "                          train=True, transform=trans, download=True)\n",
    "test_data=datasets.MNIST(root=root_ds,\n",
    "                          train=False, transform=trans, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_index(class_num, dataset, mode:str):\n",
    "    if mode == 'train':\n",
    "        class_indx = torch.nonzero(\n",
    "                dataset.train_labels == class_num * torch.ones_like(dataset.train_labels)\n",
    "        )\n",
    "\n",
    "    if mode == 'test':\n",
    "        class_indx = torch.nonzero(\n",
    "                dataset.test_labels == class_num * torch.ones_like(dataset.test_labels)\n",
    "        )\n",
    "\n",
    "    class_indx = class_indx.squeeze(1)\n",
    "    return class_indx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torchvision\\datasets\\mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "B:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_sampler = SubsetRandomSampler(get_index(8, train_data, 'train'))\n",
    "test_sampler = SubsetRandomSampler(get_index(8, test_data, 'test'))\n",
    "\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, sampler=train_sampler)\n",
    "test_loader=DataLoader(test_data, batch_size= len(test_sampler), sampler=test_sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class DirectionOnlyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DirectionOnlyLoss, self).__init__()\n",
    "        self.similarity_loss = torch.nn.CosineSimilarity()\n",
    "\n",
    "    def forward(self, output_pred, output_real):\n",
    "        y_pred_0, y_pred_1, y_pred_2, y_pred_3 = output_pred[3], output_pred[6], output_pred[9], output_pred[12]\n",
    "        y_0, y_1, y_2, y_3 = output_real[3], output_real[6], output_real[9], output_real[12]\n",
    "\n",
    "        loss_0 = torch.mean(1 - self.similarity_loss(y_pred_0.view(y_pred_0.shape[0], -1), y_0.view(y_0.shape[0], -1)))\n",
    "        loss_1 = torch.mean(1 - self.similarity_loss(y_pred_1.view(y_pred_1.shape[0], -1), y_1.view(y_1.shape[0], -1)))\n",
    "        loss_2 = torch.mean(1 - self.similarity_loss(y_pred_2.view(y_pred_2.shape[0], -1), y_2.view(y_2.shape[0], -1)))\n",
    "        loss_3 = torch.mean(1 - self.similarity_loss(y_pred_3.view(y_pred_3.shape[0], -1), y_3.view(y_3.shape[0], -1)))\n",
    "\n",
    "        total_loss = loss_0 + loss_1 + loss_2 + loss_3\n",
    "\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class MseDirectionLoss(nn.Module):\n",
    "    def __init__(self, lamda):\n",
    "        super(MseDirectionLoss, self).__init__()\n",
    "        self.lamda = lamda\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.similarity_loss = torch.nn.CosineSimilarity()\n",
    "\n",
    "    def forward(self, output_pred, output_real):\n",
    "        y_pred_0, y_pred_1, y_pred_2, y_pred_3 = output_pred[3], output_pred[6], output_pred[9], output_pred[12]\n",
    "        y_0, y_1, y_2, y_3 = output_real[3], output_real[6], output_real[9], output_real[12]\n",
    "\n",
    "        # different terms of loss\n",
    "        abs_loss_0 = self.criterion(y_pred_0, y_0)\n",
    "        loss_0 = torch.mean(1 - self.similarity_loss(y_pred_0.view(y_pred_0.shape[0], -1), y_0.view(y_0.shape[0], -1)))\n",
    "        abs_loss_1 = self.criterion(y_pred_1, y_1)\n",
    "        loss_1 = torch.mean(1 - self.similarity_loss(y_pred_1.view(y_pred_1.shape[0], -1), y_1.view(y_1.shape[0], -1)))\n",
    "        abs_loss_2 = self.criterion(y_pred_2, y_2)\n",
    "        loss_2 = torch.mean(1 - self.similarity_loss(y_pred_2.view(y_pred_2.shape[0], -1), y_2.view(y_2.shape[0], -1)))\n",
    "        abs_loss_3 = self.criterion(y_pred_3, y_3)\n",
    "        loss_3 = torch.mean(1 - self.similarity_loss(y_pred_3.view(y_pred_3.shape[0], -1), y_3.view(y_3.shape[0], -1)))\n",
    "\n",
    "        total_loss = loss_0 + loss_1 + loss_2 + loss_3 + self.lamda * (\n",
    "                abs_loss_0 + abs_loss_1 + abs_loss_2 + abs_loss_3)\n",
    "\n",
    "        return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "config = {'equal_network_size':False,\n",
    "'pretrain':True,\n",
    "'experiment_name':'local_equal_net',\n",
    "'dataset_name':'mnist',\n",
    "'normal_class':1,\n",
    "'use_bias':False,\n",
    "'equal_network_size':False}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[[[-3.0606e-02, -9.8520e-02, -1.3260e-01],\n          [ 6.8208e-03, -8.3483e-02, -1.6697e-01],\n          [ 3.1015e-02, -6.5803e-02, -1.3171e-01]],\n\n         [[ 4.7407e-02, -2.7588e-02, -5.1127e-02],\n          [ 7.0129e-02,  8.2528e-03, -1.8340e-02],\n          [ 6.9918e-02,  3.8993e-02,  1.6228e-02]],\n\n         [[ 7.0700e-02,  5.2703e-03, -4.7362e-02],\n          [ 8.4006e-02,  4.9190e-02, -1.6474e-03],\n          [ 8.5166e-03,  2.2350e-02,  5.9118e-03]],\n\n         ...,\n\n         [[ 2.7666e-02,  2.1778e-02, -9.4606e-03],\n          [ 2.5511e-02,  4.1186e-03, -3.4521e-02],\n          [ 2.0150e-02,  3.7068e-02, -1.3509e-02]],\n\n         [[ 2.1684e-02,  4.1812e-02,  5.8284e-02],\n          [ 2.7431e-02,  3.6847e-02,  3.4335e-02],\n          [-9.4839e-03,  1.9745e-02,  5.0264e-02]],\n\n         [[ 2.1769e-02, -2.1388e-02, -9.9363e-02],\n          [-5.7156e-02, -7.1328e-02, -7.7600e-02],\n          [-3.7508e-02, -2.5453e-02, -4.5096e-03]]],\n\n\n        [[[-1.3319e-02, -7.7979e-02, -1.3496e-01],\n          [-3.7411e-02, -8.1807e-02, -1.4195e-01],\n          [-4.1913e-02, -1.0756e-01, -1.6164e-01]],\n\n         [[-6.8725e-03,  4.8598e-02,  1.5008e-02],\n          [ 1.8636e-02,  9.8393e-03, -1.5973e-02],\n          [ 9.5164e-04, -3.2665e-02, -3.5824e-02]],\n\n         [[ 1.4780e-02, -1.4260e-02, -4.4468e-02],\n          [-1.8438e-02,  1.4841e-02, -8.2337e-02],\n          [ 1.8329e-02,  2.1435e-03,  9.0911e-03]],\n\n         ...,\n\n         [[ 4.0342e-02,  3.6146e-02,  2.5515e-02],\n          [ 1.5779e-02,  3.1012e-03, -1.0942e-02],\n          [ 2.3790e-02,  1.6440e-02, -2.5835e-02]],\n\n         [[-2.2844e-02,  2.5371e-03, -2.1714e-02],\n          [ 3.9534e-04, -6.4903e-03,  1.6979e-02],\n          [-4.7200e-03, -2.2301e-02, -2.1298e-02]],\n\n         [[-2.8434e-02, -2.6771e-02,  2.7432e-02],\n          [-5.8088e-02, -5.5869e-02,  7.0289e-02],\n          [-6.4470e-02, -3.8172e-02,  4.1569e-02]]],\n\n\n        [[[ 1.2508e-02,  2.4738e-02,  5.3893e-02],\n          [-2.5838e-02, -1.6176e-02,  2.8344e-02],\n          [ 1.2948e-02,  9.0717e-03,  2.8181e-02]],\n\n         [[-7.9309e-02, -8.8828e-02, -5.5737e-02],\n          [-4.8359e-02, -1.1139e-01, -1.0901e-02],\n          [ 3.4640e-02,  2.3298e-02,  1.1002e-01]],\n\n         [[-4.3616e-02, -1.6598e-02, -1.0547e-02],\n          [ 2.8982e-02,  4.5279e-02,  1.6869e-02],\n          [ 8.8168e-02,  1.2599e-01,  7.2292e-02]],\n\n         ...,\n\n         [[ 1.3967e-03,  1.5333e-02, -1.7196e-02],\n          [-8.3107e-03, -1.2905e-02, -1.4394e-03],\n          [ 6.3471e-03,  1.7825e-03, -3.3770e-02]],\n\n         [[-7.9354e-03, -5.8610e-03, -7.6292e-05],\n          [ 6.8661e-04, -6.0019e-03,  1.0119e-02],\n          [ 3.0581e-02,  1.6821e-02,  3.2570e-02]],\n\n         [[ 5.9351e-02, -7.4398e-03,  3.8274e-02],\n          [-2.0792e-02, -4.8833e-02,  4.0274e-02],\n          [ 2.3138e-02,  7.4794e-03,  3.5027e-02]]],\n\n\n        ...,\n\n\n        [[[-4.5464e-02, -2.9275e-02,  1.0282e-02],\n          [-4.6952e-02, -4.9473e-02,  1.7632e-02],\n          [-4.3815e-02, -2.4871e-02, -2.4908e-02]],\n\n         [[-1.9359e-02,  1.5948e-02, -6.3554e-02],\n          [ 3.0096e-02,  2.8515e-02, -6.4439e-02],\n          [-1.4547e-02,  2.2238e-03, -6.3371e-02]],\n\n         [[-2.7915e-02, -2.1738e-02, -5.1691e-02],\n          [ 1.0889e-02, -5.1994e-02, -5.4649e-02],\n          [-3.9741e-02,  5.2832e-04,  3.5375e-02]],\n\n         ...,\n\n         [[-1.9130e-03,  1.0995e-03, -7.4082e-03],\n          [ 1.8428e-03,  8.2602e-03,  1.8680e-02],\n          [ 1.1709e-02,  6.9263e-03,  3.3630e-02]],\n\n         [[ 8.9195e-03,  3.2807e-02,  3.9282e-02],\n          [-2.5044e-03,  1.7645e-03,  1.4056e-02],\n          [-5.4708e-03,  9.5572e-03,  2.8639e-02]],\n\n         [[-3.0241e-02, -6.7225e-02, -7.4299e-02],\n          [-3.6222e-02, -9.7721e-03,  6.1669e-02],\n          [-1.6392e-02,  5.8156e-02,  1.2894e-01]]],\n\n\n        [[[ 4.0321e-02,  3.7677e-02,  1.7181e-02],\n          [ 4.0298e-02,  2.9479e-02,  1.6698e-02],\n          [-4.8739e-03,  2.1128e-02, -2.6295e-03]],\n\n         [[ 3.1079e-02, -1.6475e-02,  1.0769e-02],\n          [-5.8626e-02, -4.6721e-02, -2.7764e-02],\n          [-3.1245e-02,  1.7635e-02, -1.2211e-02]],\n\n         [[-9.8675e-02, -9.8915e-02, -1.3225e-01],\n          [ 7.3214e-02, -7.5238e-03, -7.4033e-02],\n          [ 1.7070e-01,  1.8346e-01,  3.3906e-02]],\n\n         ...,\n\n         [[ 2.5318e-02,  3.2680e-02,  5.2874e-03],\n          [-4.1894e-03,  2.0011e-02,  1.6021e-02],\n          [-4.8276e-03, -2.9130e-02,  7.4975e-04]],\n\n         [[ 7.1959e-03, -5.1528e-03,  5.1333e-03],\n          [-8.6466e-04,  1.2417e-02,  2.0805e-02],\n          [ 2.4862e-03, -1.3194e-02,  3.6563e-03]],\n\n         [[ 3.2415e-02,  1.0823e-02,  3.1720e-02],\n          [-8.4911e-03,  5.9831e-02,  3.4606e-02],\n          [-2.0674e-02,  1.6525e-02, -1.3183e-02]]],\n\n\n        [[[-6.6955e-02,  1.0821e-02,  7.9260e-02],\n          [ 1.0361e-02, -3.3380e-02,  5.2775e-02],\n          [-3.8372e-02, -3.0964e-02,  6.5422e-02]],\n\n         [[ 5.4925e-02, -1.9160e-01,  9.9709e-02],\n          [-1.8754e-01,  1.3248e-02,  2.4748e-01],\n          [-5.6662e-03,  2.8737e-02, -8.9787e-02]],\n\n         [[-1.4905e-01, -1.2974e-01,  1.7649e-01],\n          [-1.5774e-01,  1.5130e-01,  8.4126e-02],\n          [ 9.4988e-02,  8.5186e-02, -3.3635e-02]],\n\n         ...,\n\n         [[ 1.2278e-02,  3.3348e-02, -1.0524e-02],\n          [ 5.0310e-02, -9.1280e-03, -3.3890e-02],\n          [ 1.3459e-02, -2.9601e-02,  2.6862e-02]],\n\n         [[ 3.1006e-02,  2.8481e-02,  5.2361e-03],\n          [ 3.8914e-03, -1.8899e-02, -2.1819e-02],\n          [-8.4505e-03, -3.6632e-02, -1.9476e-02]],\n\n         [[ 2.3835e-02,  4.5658e-02,  6.7297e-02],\n          [ 1.1103e-02,  3.2035e-02, -5.8449e-02],\n          [ 2.6805e-02, -9.3975e-02, -4.0504e-02]]]], device='cuda:0',\n       requires_grad=True)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.features[2].weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to ./pretrain_models/ok\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0.00/528M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "333d95e4d6a84d52807c8dc2f4085dc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_9172/832400776.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menviron\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'TORCH_HOME'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'./pretrain_models/ok'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mvgg16\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'vgg16-397923af.pth'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torchvision\\models\\vgg.py\u001B[0m in \u001B[0;36mvgg16\u001B[1;34m(pretrained, progress, **kwargs)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[0mprogress\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mbool\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIf\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdisplays\u001B[0m \u001B[0ma\u001B[0m \u001B[0mprogress\u001B[0m \u001B[0mbar\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mdownload\u001B[0m \u001B[0mto\u001B[0m \u001B[0mstderr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    161\u001B[0m     \"\"\"\n\u001B[1;32m--> 162\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_vgg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'vgg16'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'D'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpretrained\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprogress\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torchvision\\models\\vgg.py\u001B[0m in \u001B[0;36m_vgg\u001B[1;34m(arch, cfg, batch_norm, pretrained, progress, **kwargs)\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mVGG\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmake_layers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcfgs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcfg\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_norm\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_norm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mpretrained\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 99\u001B[1;33m         state_dict = load_state_dict_from_url(model_urls[arch],\n\u001B[0m\u001B[0;32m    100\u001B[0m                                               progress=progress)\n\u001B[0;32m    101\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torch\\hub.py\u001B[0m in \u001B[0;36mload_state_dict_from_url\u001B[1;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001B[0m\n\u001B[0;32m    584\u001B[0m             \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mHASH_REGEX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msearch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# r is Optional[Match[str]]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m             \u001B[0mhash_prefix\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mr\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m         \u001B[0mdownload_url_to_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0murl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcached_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhash_prefix\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprogress\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprogress\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_is_legacy_zip_format\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcached_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\site-packages\\torch\\hub.py\u001B[0m in \u001B[0;36mdownload_url_to_file\u001B[1;34m(url, dst, hash_prefix, progress)\u001B[0m\n\u001B[0;32m    472\u001B[0m                   unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n\u001B[0;32m    473\u001B[0m             \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 474\u001B[1;33m                 \u001B[0mbuffer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m8192\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    475\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    476\u001B[0m                     \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\http\\client.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    460\u001B[0m             \u001B[1;31m# Amount is given, implement using readinto\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    461\u001B[0m             \u001B[0mb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbytearray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mamt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 462\u001B[1;33m             \u001B[0mn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadinto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    463\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mmemoryview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtobytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    464\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\http\\client.py\u001B[0m in \u001B[0;36mreadinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    504\u001B[0m         \u001B[1;31m# connection, and the user is reading more bytes than will be provided\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    505\u001B[0m         \u001B[1;31m# (for example, reading in 1k chunks)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 506\u001B[1;33m         \u001B[0mn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadinto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    507\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mn\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    508\u001B[0m             \u001B[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    702\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    703\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 704\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    705\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    706\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\ssl.py\u001B[0m in \u001B[0;36mrecv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1239\u001B[0m                   \u001B[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001B[0m \u001B[1;33m%\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1240\u001B[0m                   self.__class__)\n\u001B[1;32m-> 1241\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnbytes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1242\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1243\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnbytes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mB:\\Anaconda_install_path\\envs\\deeplearning\\lib\\ssl.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1097\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1098\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mbuffer\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1099\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1100\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1101\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "vgg16('vgg16-397923af.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer : 0 Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 1 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 2 ReLU(inplace=True)\n",
      "layer : 3 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 4 ReLU(inplace=True)\n",
      "layer : 5 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 6 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 7 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 8 ReLU(inplace=True)\n",
      "layer : 9 Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 10 ReLU(inplace=True)\n",
      "layer : 11 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 12 Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 13 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 14 ReLU(inplace=True)\n",
      "layer : 15 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 16 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 17 ReLU(inplace=True)\n",
      "layer : 18 Conv2d(16, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 19 ReLU(inplace=True)\n",
      "layer : 20 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 21 Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 22 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 23 ReLU(inplace=True)\n",
      "layer : 24 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 25 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 26 ReLU(inplace=True)\n",
      "layer : 27 Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 28 ReLU(inplace=True)\n",
      "layer : 29 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 30 Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 31 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 32 ReLU(inplace=True)\n",
      "layer : 33 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 34 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 35 ReLU(inplace=True)\n",
      "layer : 36 Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 37 ReLU(inplace=True)\n",
      "layer : 38 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "continue_train = False\n",
    "os.environ['TORCH_HOME'] = './pretrain_models'\n",
    "if continue_train:\n",
    "    vgg, discriminator = get_networks(config, load_checkpoint=True)\n",
    "else:\n",
    "    vgg, discriminator = get_networks(config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 512, 1, 1])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator(X)[-1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        _, self.vgg = get_networks(config)\n",
    "        self.adverse_layer = nn.Sequential(nn.Linear(512 , 1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.adverse_layer(\n",
    "            self.vgg(x)[-1].flatten(1)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer : 0 Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 1 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 2 ReLU(inplace=True)\n",
      "layer : 3 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 4 ReLU(inplace=True)\n",
      "layer : 5 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 6 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 7 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 8 ReLU(inplace=True)\n",
      "layer : 9 Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 10 ReLU(inplace=True)\n",
      "layer : 11 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 12 Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 13 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 14 ReLU(inplace=True)\n",
      "layer : 15 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 16 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 17 ReLU(inplace=True)\n",
      "layer : 18 Conv2d(16, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 19 ReLU(inplace=True)\n",
      "layer : 20 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 21 Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 22 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 23 ReLU(inplace=True)\n",
      "layer : 24 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 25 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 26 ReLU(inplace=True)\n",
      "layer : 27 Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 28 ReLU(inplace=True)\n",
      "layer : 29 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "layer : 30 Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 31 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 32 ReLU(inplace=True)\n",
      "layer : 33 Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 34 BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer : 35 ReLU(inplace=True)\n",
      "layer : 36 Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer : 37 ReLU(inplace=True)\n",
      "layer : 38 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "os.environ['TORCH_HOME'] = './pretrain_models'\n",
    "disc = Discriminator(config).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "Discriminator(\n  (vgg): VGG(\n    (features): Sequential(\n      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): ReLU(inplace=True)\n      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (8): ReLU(inplace=True)\n      (9): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (10): ReLU(inplace=True)\n      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (12): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (14): ReLU(inplace=True)\n      (15): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (16): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (17): ReLU(inplace=True)\n      (18): Conv2d(16, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (19): ReLU(inplace=True)\n      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (21): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (22): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (23): ReLU(inplace=True)\n      (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (26): ReLU(inplace=True)\n      (27): Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (28): ReLU(inplace=True)\n      (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (30): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (32): ReLU(inplace=True)\n      (33): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (34): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (35): ReLU(inplace=True)\n      (36): Conv2d(16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (37): ReLU(inplace=True)\n      (38): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n  )\n  (adverse_layer): Sequential(\n    (0): Linear(in_features=512, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 1])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc(X).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Criteria And Optimizers\n",
    "direction_loss_only = False\n",
    "lamda = 0.01\n",
    "\n",
    "if direction_loss_only:\n",
    "    criterion_disc_layers = DirectionOnlyLoss()\n",
    "else:\n",
    "    criterion_disc_layers = MseDirectionLoss(lamda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_9172/92805113.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mreal_images\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m                 \u001B[0mreal_images\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreal_images\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m             \u001B[0mreal_images\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mVariable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreal_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m             \u001B[0mgen_imgs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreal_images\u001B[0m \u001B[1;31m###############################\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(num_epochs + 1):\n",
    "        discriminator.train()\n",
    "        epoch_loss = 0\n",
    "        for real_images, _ in train_loader:\n",
    "            if real_images.shape[1] == 1:\n",
    "                real_images = real_images.repeat(1, 3, 1, 1)\n",
    "            real_images = Variable(real_images).cuda()\n",
    "            gen_imgs = real_images ###############################\n",
    "\n",
    "            # Layer Features Learning\n",
    "            d_loss_layers_real = criterion_disc_layers(discriminator.forward(real_images), vgg(real_images))\n",
    "            d_loss_layers_fake = criterion_disc_layers(discriminator.forward(gen_imgs), vgg(gen_imgs))\n",
    "            d_loss_layers = 0.5*(d_loss_layers_real + d_loss_layers_fake)\n",
    "\n",
    "\n",
    "\n",
    "            # Adverserial Learning\n",
    "            total_loss = d_loss_layers\n",
    "\n",
    "            # Add loss to the list\n",
    "            epoch_loss += total_loss.item()\n",
    "            losses.append(total_loss.item())\n",
    "\n",
    "            # Clear the previous gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Compute gradients\n",
    "            total_loss.backward()\n",
    "            # Adjust weights\n",
    "            optimizer.step()\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, epoch_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.5455, device='cuda:0', grad_fn=<AddBackward0>)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_loss_layers_real"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.]],\n\n         [[0.]],\n\n         [[0.]],\n\n         ...,\n\n         [[0.]],\n\n         [[0.]],\n\n         [[0.]]],\n\n\n        [[[0.]],\n\n         [[0.]],\n\n         [[0.]],\n\n         ...,\n\n         [[0.]],\n\n         [[0.]],\n\n         [[0.]]],\n\n\n        [[[0.]],\n\n         [[0.]],\n\n         [[0.]],\n\n         ...,\n\n         [[0.]],\n\n         [[0.]],\n\n         [[0.]]],\n\n\n        ...,\n\n\n        [[[0.]],\n\n         [[0.]],\n\n         [[0.]],\n\n         ...,\n\n         [[0.]],\n\n         [[0.]],\n\n         [[0.]]],\n\n\n        [[[0.]],\n\n         [[0.]],\n\n         [[0.]],\n\n         ...,\n\n         [[0.]],\n\n         [[0.]],\n\n         [[0.]]],\n\n\n        [[[0.]],\n\n         [[0.]],\n\n         [[0.]],\n\n         ...,\n\n         [[0.]],\n\n         [[0.]],\n\n         [[0.]]]], device='cuda:0', grad_fn=<MaxPool2DWithIndicesBackward0>)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator(X)[-1].flatten(1).mean(1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "343984"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        ...,\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n\n\n        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]],\n\n         [[-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          ...,\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.],\n          [-1., -1., -1.,  ..., -1., -1., -1.]]]], device='cuda:0')"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}