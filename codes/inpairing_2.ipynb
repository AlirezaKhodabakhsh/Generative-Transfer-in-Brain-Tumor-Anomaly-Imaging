{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Libs"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ApZFC-i7xzTq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "i5ANNZnpxzTs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.nn import init\n",
    "from torchvision.utils import make_grid\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "id": "970zdRQkxzTu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Anomaly_Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root\n",
    "                 ):\n",
    "        super(Anomaly_Dataset, self).__init__()\n",
    "\n",
    "        self.data = Anomaly_Dataset.load_dataset(root)\n",
    "        self.image, self.label = Anomaly_Dataset.get_numpy(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x, y =  self.image[item], self.label[item]\n",
    "\n",
    "        # RGB -> GRAY : (H, W)\n",
    "        x = x[:,:,0]\n",
    "\n",
    "        # (1, H, W)\n",
    "        x = Anomaly_Dataset.normalization(x)\n",
    "        #x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(path):\n",
    "        img_rows = 128\n",
    "        img_cols = 128\n",
    "        return image_dataset_from_directory(directory = path,\n",
    "                                               label_mode = 'int',\n",
    "                                               color_mode = 'rgb',\n",
    "                                               shuffle = False,\n",
    "                                               batch_size = None,\n",
    "                                               image_size = (img_rows, img_cols),\n",
    "                                               crop_to_aspect_ratio = True)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_numpy(PrefetchDataset):\n",
    "        \"\"\"\n",
    "        return:\n",
    "            (N, H, W, C) , (N,)\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        labels = []\n",
    "        for (image, label) in PrefetchDataset:\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def rgb_2_gray(x):\n",
    "        \"\"\"\n",
    "        (H, W, C) --> (H, W)\n",
    "        \"\"\"\n",
    "        return cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalization(x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x : np.array : (H, W)\n",
    "\n",
    "        Return:\n",
    "            np.array : (H, W)\n",
    "        \"\"\"\n",
    "        x = x - x.min(keepdims=True)\n",
    "        x = x / x.max(keepdims=True)\n",
    "        x = x - 0.5\n",
    "        return  x / 0.5"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "uuKZIDz3xzTu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Noise"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Jgfu0tg1xzTv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def get_noise(num_z, z_dim, device='cpu'):\n",
    "    # mean, std = 0, 1\n",
    "    #return torch.empty(num_z, z_dim, 1, 1).normal_(mean, std).to(device)\n",
    "    return torch.randn(num_z, z_dim, 1, 1, device=device)\n",
    "\"\"\""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "tMX2JWLxxzTv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Net"
   ],
   "metadata": {
    "collapsed": false,
    "id": "e4j8LhSKxzTw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, init_features):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = Encoder._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = Encoder._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = Encoder._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = Encoder._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bottleneck = Encoder._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        return bottleneck, enc4, enc3, enc2, enc1\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, init_features, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = Decoder._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = Decoder._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = Decoder._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = Decoder._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, bottleneck, enc4, enc3, enc2, enc1):\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.tanh(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, init_features):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder = Encoder(in_channels, features)\n",
    "        self.decoder = Decoder(features, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.bottleneck, self.enc4, self.enc3, self.enc2, self.enc1 = self.encoder(x)\n",
    "        x_hat = self.decoder(self.bottleneck, self.enc4, self.enc3, self.enc2, self.enc1)\n",
    "        return x_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "N, C, H, W = 1, 1, 128, 128\n",
    "x = torch.ones(N, C, H, W)\n",
    "unet = UNet(1, 1, 8)\n",
    "print(unet(x).shape)\n",
    "count_parameters(unet)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "N, C, H, W = 1, 1, 128, 128\n",
    "x = torch.ones(N, C, H, W)\n",
    "gen = Generator(1, 1, 8)\n",
    "print(gen(x).shape)\n",
    "count_parameters(gen)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAnnqeIRxzTw",
    "outputId": "c73a9204-5a8e-45c3-fed3-0b531e1f4bf4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Change activation to RELU\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self , c_dim , df_dim):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        # torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "        #                          output_padding=0,groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            Critic._block(c_dim, df_dim),\n",
    "            Critic._block(df_dim, df_dim*2),\n",
    "            Critic._block(df_dim*2, df_dim*4),\n",
    "            Critic._block(df_dim*4, 1, padding=0, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def forward(self,inp):\n",
    "        return self.critic(\n",
    "            inp\n",
    "        ).flatten(1) # (N , 1 , 1, 1 )\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, out_channels, kernel_size=4, stride=3, padding=1, final_layer=False):\n",
    "        if final_layer:\n",
    "            return nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(negative_slope=0.2)\n",
    "            )"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QjpsRN1oxzTx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "N, C, H, W = 1, 1, 128, 128\n",
    "x = torch.ones(N, C, H, W)\n",
    "crit = Critic(C, 64)\n",
    "print(crit(x).shape)\n",
    "count_parameters(crit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, c_dim , df_dim=32):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.fea1 = nn.Sequential(\n",
    "            SpectralNorm(nn.Conv2d(c_dim, df_dim, kernel_size=5, stride=2, padding=0)),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            SpectralNorm(nn.Conv2d(df_dim, df_dim*2, kernel_size=5, stride=2, padding=0)),\n",
    "            nn.BatchNorm2d(df_dim*2, 0.5), nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            SpectralNorm(nn.Conv2d(df_dim*2, df_dim*4, kernel_size=3, stride=2, padding=0)),\n",
    "            nn.BatchNorm2d(df_dim*4, 0.5), nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            SpectralNorm(nn.Conv2d(df_dim*4, df_dim*8, kernel_size=3, stride=2, padding=0)),\n",
    "            nn.BatchNorm2d(df_dim*8, 0.5), nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=6, stride=6))\n",
    "\n",
    "        self.concat = nn.Sequential(nn.Dropout(0.2), nn.Linear(256, 128),\n",
    "                                    nn.Dropout(0.2), nn.Linear(128, 1)\n",
    "                                )\n",
    "\n",
    "    def forward(self, img):\n",
    "        fea1_out = self.fea1(img).flatten(start_dim=1)\n",
    "\n",
    "        self.concat = nn.Sequential(nn.Dropout(0.2), nn.Linear(fea1_out.shape[1], int(fea1_out.shape[1]/2)),\n",
    "                                    nn.Dropout(0.2), nn.Linear(int(fea1_out.shape[1]/2), 1)\n",
    "                                ).to(self.fea1[0].module.bias.device)\n",
    "        validity = self.concat(fea1_out)\n",
    "\n",
    "        return validity\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "N, C, H, W = 1, 1, 128, 128\n",
    "x = torch.ones(N, C, H, W)\n",
    "crit = Critic(C, 8)\n",
    "print(crit(x).shape)\n",
    "count_parameters(crit)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fc7jVevexzTx",
    "outputId": "46bf4317-2fec-4f66-a989-97d6c051589b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss"
   ],
   "metadata": {
    "collapsed": false,
    "id": "qCukXzgpxzTx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_epsilon(N_epsilon, device='cpu'):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        N_epsilon : Number of epsilons\n",
    "    Output:\n",
    "        e.g. shape : (128, 1, 1, 1)\n",
    "    \"\"\"\n",
    "    return torch.rand(N_epsilon, 1, 1, 1, device=device, requires_grad=True)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bpJpCPNnxzTy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_gradient(crit, data):\n",
    "    \"\"\"\n",
    "    Return the gradient of the critic's scores with respect to mixes of real and fake images.\n",
    "    Parameters:\n",
    "        dis: the critic model\n",
    "        data: a batch of data\n",
    "    Returns:\n",
    "        gradient: the gradient of the discriminator's scores, with respect to data\n",
    "    \"\"\"\n",
    "\n",
    "    # True require_grad of Data\n",
    "    data.requires_grad_()\n",
    "    # Calculate the discriminator's scores on the data\n",
    "    score = crit(data)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the data\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=data,\n",
    "        outputs=score,\n",
    "        # These other parameters have to do with the pytorch autograd engine works\n",
    "        grad_outputs=torch.ones_like(score),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return gradient"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lpAaC4LOxzTy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    '''\n",
    "    Return the gradient penalty, given a gradient.\n",
    "    Given a batch of data gradients, you calculate the magnitude of each data's gradient\n",
    "    and penalize the mean quadratic distance of each magnitude to 1.\n",
    "\n",
    "    Parameters:\n",
    "        gradient: the gradient of the discriminator's scores, with respect to the data\n",
    "        e.g shape  : (128, 1, 28, 28)\n",
    "\n",
    "    Returns:\n",
    "        penalty: the gradient penalty\n",
    "        e.g shaoe : (scaler)\n",
    "    '''\n",
    "\n",
    "    # Flatten the gradients so that each row captures one image\n",
    "    # e.g shape  : (128, 1, 28, 28) ==> (128, 784)\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    # Calculate the magnitude of every row\n",
    "    # e.g shape : (128, 784) ==> (128, 1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "\n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    # e.g shape : (128, 1) ==> (scaler)\n",
    "    penalty = ( ( gradient_norm - 1.0 )**2 ).mean(dim=0)\n",
    "    return penalty"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "t40HvVtZxzTy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_crit_loss(\n",
    "    image,\n",
    "    gen, crit,\n",
    "    c_lambda,\n",
    "    device):\n",
    "    '''\n",
    "    Parameters:\n",
    "        All as same as DCGAN Losses\n",
    "    Returns:\n",
    "        dis_loss: a scalar for the dis's loss\n",
    "    '''\n",
    "    #x_no_tumor_fake = gen(x_tumor #+ get_noise(x_tumor, device=device)).detach()\n",
    "\n",
    "    image_hat = gen(\n",
    "        image\n",
    "    ).detach()\n",
    "\n",
    "    # Mixed \"real\" with \"fake\"\n",
    "    #epsilon = get_epsilon(N_epsilon = x_no_tumor.shape[0], device=device)\n",
    "    epsilon = get_epsilon(N_epsilon = image.shape[0], device=device)\n",
    "\n",
    "    #mixed_images = x_no_tumor * epsilon + x_no_tumor_fake * (1 - epsilon)\n",
    "    mixed_images = image * epsilon + image_hat * (1 - epsilon)\n",
    "\n",
    "    # Calculate Gradient Penalty (use prior funcs)\n",
    "    gp = gradient_penalty(get_gradient(crit, mixed_images))\n",
    "    # Calculate \"Line 7\" of \"Algorithm 1\" in main paper\n",
    "    #return ( dis(x_no_tumor_fake) - dis(x_no_tumor) + c_lambda * gp ).mean(dim=0)\n",
    "    return ( crit(image_hat) - crit(image) + c_lambda * gp ).mean(dim=0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Hrvly6ZfxzTz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_gen_loss(\n",
    "      image,\n",
    "      gen, crit):\n",
    "    '''\n",
    "    Return the loss of a generator.\n",
    "    Parameters:\n",
    "\n",
    "    Returns:\n",
    "       a scalar loss value for the current batch of the generator\n",
    "    '''\n",
    "    image_hat = gen(\n",
    "        image\n",
    "    )\n",
    "    # Calculate \"Line 12\" of \"Algorithm 1\" in main paper\n",
    "    return ( -crit(image_hat) ).mean(dim=0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ANuSFJEoxzTz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper"
   ],
   "metadata": {
    "collapsed": false,
    "id": "K87ENRNzxzTz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ploter(image, image_hat):\n",
    "    \"\"\"\n",
    "    (H, W)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    #plt.imshow(image_hat, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.imshow(image_hat)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Reconstruct\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    #plt.imshow(image, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "X1zpzDV5xzTz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weights_init(submodules):\n",
    "    if isinstance(submodules, nn.Conv2d) or isinstance(submodules, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(submodules.weight, 0.0, 0.02)\n",
    "        #torch.nn.init.normal_(submodules.bias, 0.0, 0.02)\n",
    "    if isinstance(submodules, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(submodules.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(submodules.bias, 0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NWECilNgxzT0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 128, 128)):\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze(), cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "WadHz_RHxzT0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparamters"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zo_UBFjGxzT0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c_dim , gf_dim = 1, 8\n",
    "df_dim = 64\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# num_train = 80\n",
    "batch_size =20\n",
    "# batch_size = 10, 20, 40, 80\n",
    "\n",
    "\n",
    "lr_gen, lr_crit = 0.002, 0.002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "# epochs\n",
    "epochs= 5000\n",
    "disp_freq=1\n",
    "display_step=1\n",
    "\n",
    "crit_repeats=5\n",
    "c_lambda = 10\n",
    "\n",
    "step_bins = 1"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "W4VQEe_6xzT0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen = Generator(c_dim, c_dim, gf_dim).to(device)\n",
    "crit = Critic(c_dim, df_dim).to(device)\n",
    "\n",
    "# Initialize\n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)\n",
    "\n",
    "\n",
    "# Loss function\n",
    "#criterion=nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizers\n",
    "optim_crit = torch.optim.Adam(crit.parameters(), lr=lr_crit, betas=(beta_1, beta_2))\n",
    "optim_gen = torch.optim.Adam(gen.parameters(), lr=lr_gen, betas=(beta_1, beta_2))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MCRCd1q0xzT1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "tFC9t5b2xzT1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#root = \"/content/drive/MyDrive/MRI Arman/kaggle1/no\"\n",
    "root = \"./../dataset/kaggle1/no\"\n",
    "dataset = Anomaly_Dataset(root)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PHa2iEkxzT1",
    "outputId": "f9e04382-c9bb-4f3d-de80-42ec01d8a4d1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#sampler\n",
    "num_data = dataset.__len__()\n",
    "num_valid = 11\n",
    "num_train = num_data - num_valid #80\n",
    "\n",
    "indices = list(range(num_data))\n",
    "train_idx, valid_idx = indices[num_valid:], indices[:num_valid]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset, batch_size= batch_size, sampler=train_sampler)\n",
    "valid_loader=DataLoader(dataset, batch_size= num_valid, sampler=valid_sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(train_loader, 1):\n",
    "    x=x\n",
    "    y=y"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "LZZsB5K8xzT1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x[0], cmap='gray', vmin=-1, vmax=1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "_ccNPLsRxzT2",
    "outputId": "7582532b-9802-4406-f547-e1ced5f5d0d0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "i4wq4u-8xzT2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "u2628G3SxzT2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cur_step = 0\n",
    "generator_losses = []\n",
    "critic_losses = []\n",
    "loss_inf = np.Inf\n",
    "mse_losses = []"
   ],
   "metadata": {
    "id": "UKfM8_NELBpZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    print(60 * \"#\")\n",
    "    print(6 * \"#\" + \" Epoch \" + str(epoch) + \" \" + 45 * \"#\")\n",
    "    print(60 * \"#\")\n",
    "\n",
    "    # Set mode on \"train mode\"\n",
    "    gen.train()\n",
    "    crit.train()\n",
    "\n",
    "    for image_train,_ in train_loader:\n",
    "        cur_batch_size = len(image_train)\n",
    "        split = int(batch_size/2)\n",
    "\n",
    "        image_gen = image_train[:split].unsqueeze(1).to(device)\n",
    "        image_crit = image_train[split:].unsqueeze(1).to(device)\n",
    "\n",
    "\n",
    "        # Discriminator Learning\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "          optim_crit.zero_grad()\n",
    "          crit_loss  = get_crit_loss(image_crit, gen, crit, c_lambda, device=device)\n",
    "          crit_loss .backward(retain_graph=True)\n",
    "          optim_crit.step()\n",
    "          mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "        critic_losses += [mean_iteration_critic_loss]\n",
    "\n",
    "        # Generator Learning\n",
    "        optim_gen.zero_grad()\n",
    "        gen_loss  = get_gen_loss(image_gen, gen, crit)\n",
    "        gen_loss .backward()\n",
    "        optim_gen.step()\n",
    "        generator_losses += [gen_loss.item()]\n",
    "\n",
    "    for image_valid,_ in valid_loader:\n",
    "        image_valid = image_valid.unsqueeze(1).to(device)\n",
    "        image_hat = gen(image_valid)\n",
    "        differ = nn.MSELoss()\n",
    "        mse_loss = differ(image_hat, image_valid)\n",
    "        mse_losses += [mse_loss.item()]\n",
    "\n",
    "\n",
    "    ### Visualization code ###\n",
    "    if cur_step % display_step == 0 and cur_step > 0:\n",
    "        gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "        crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "        mse_mean = sum(mse_losses[-display_step:]) / display_step\n",
    "\n",
    "        print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "        print(f\"Epoch {epoch}, step {cur_step}: MSE loss: {mse_mean}\")\n",
    "\n",
    "\n",
    "        i=math.floor(np.random.uniform(0, image_valid.shape[0]))\n",
    "\n",
    "        plt.figure()\n",
    "        ploter(image_valid[i,0].detach().cpu(), image_hat[i,0].detach().cpu())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        num_examples = (len(mse_losses) // step_bins) * step_bins\n",
    "        plt.plot(\n",
    "            range(num_examples // step_bins),\n",
    "            torch.Tensor(mse_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "            label=\"MSE Loss\"\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "        plt.plot(\n",
    "            range(num_examples // step_bins),\n",
    "            torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "            label=\"Generator Loss\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            range(num_examples // step_bins),\n",
    "            torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "            label=\"Critic Loss\"\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    cur_step += 1\n",
    "\n",
    "    \"\"\"\n",
    "    if epoch % 250 == 0:\n",
    "      root_save = f\"/content/drive/MyDrive/MRI Arman/epoch_{epoch}.pt\"\n",
    "      torch.save({'epoch': epoch, 'Generator': gen.state_dict(), 'Critic': crit.state_dict()},\n",
    "                  root_save)\n",
    "    \"\"\""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sF1KGwqWxzT2",
    "outputId": "893a7644-6348-472e-9729-9deb62a1550e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epoch"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIJe5VKQ78t1",
    "outputId": "cb0ccc17-2306-4e7d-fa30-24345511b209"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epoch % 250 == 0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-KJx_rK75ZM",
    "outputId": "e1adbd82-9ded-4442-bbed-778156efedbe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "z_dim , c_dim , gf_dim = 100, 1, 64\n",
    "df_dim = 64\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "batch_size =25\n",
    "\n",
    "\n",
    "lr_gen, lr_crit = 0.0002, 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "\n",
    "# epochs\n",
    "epochs= 300\n",
    "disp_freq=1\n",
    "display_step=5\n",
    "\n",
    "crit_repeats=5\n",
    "c_lambda = 10"
   ],
   "metadata": {
    "id": "l6SKei0N620v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "9Y8y-o7L64WI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen.state_dict()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "So98y2jlxzT2",
    "outputId": "7be985a3-209a-4538-b952-a6e795d4c41f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image.shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pX-4A7YLxzT2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "root_save = f\"/content/drive/MyDrive/MRI Arman/kaggle1/epoch_{epoch}.pt\"\n",
    "torch.save({'epoch': epoch, 'Generator': gen.state_dict(), 'Critic': crit.state_dict()},\n",
    "            root_save)"
   ],
   "metadata": {
    "id": "9Z9Ae5Ba6FOm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "elmjiuqbxzT3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root = \"./../dataset/kaggle1/no\"\n",
    "dataset = Anomaly_Dataset(root)\n",
    "dataloader_normal = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3p3MpdQbxzT3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, y in dataloader_normal:\n",
    "    x=x\n",
    "    y=y"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "V231KKFuxzT3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x[0], cmap='gray', vmin=-1, vmax=1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "8nT8oiobxzT3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZilktojMxzT4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-yYJbWE2xzT4"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}