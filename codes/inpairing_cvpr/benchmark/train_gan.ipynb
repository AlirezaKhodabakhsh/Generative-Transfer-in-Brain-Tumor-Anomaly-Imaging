{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Libs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.datasets import CelebA\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "# main libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import torchvision.transforms.functional as TF\n",
    "import cv2\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.nn import init\n",
    "from torchvision.utils import make_grid\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from skimage import transform\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in a uniform grid.\n",
    "    '''\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ploter(image, image_hat):\n",
    "    \"\"\"\n",
    "    (H, W)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    #plt.imshow(image_hat, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.imshow(image_hat)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Reconstruct\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    #plt.imshow(image, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, channels):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.linear_layer = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.linear_layer(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        image = self.conv_layers(out)\n",
    "        return image\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels, img_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # self.ds_size = img_size // 2 ** 4 # for img_size = 96\n",
    "        self.ds_size = 2 # for img_size = 28\n",
    "        self.adverse_layer = nn.Sequential(nn.Linear(128 * self.ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, image):\n",
    "        out = self.conv_layers(image)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adverse_layer(out)\n",
    "        return validity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "G = Generator(28, 100, 1)\n",
    "x = torch.ones(1, 1, 28, 28).to(torch.float)\n",
    "z = torch.FloatTensor(np.random.normal(0, 1, (x.shape[0], 100)))\n",
    "G(z).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST\n",
    "D = Discriminator(1, 28)\n",
    "x = torch.ones(1, 1, 28, 28).to(torch.float)\n",
    "D(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root_save = \"./best_models\"\n",
    "root_ds = \"./MNIST\"\n",
    "\n",
    "batch_size = 128\n",
    "img_size = 28\n",
    "latent_dim = 100\n",
    "channels = 1\n",
    "num_epochs = 1000\n",
    "sample_interval = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize((0.5,) , (0.5,))\n",
    "])\n",
    "\n",
    "train_data=datasets.MNIST(root=root_ds,\n",
    "                          train=True, transform=trans, download=True)\n",
    "test_data=datasets.MNIST(root=root_ds,\n",
    "                          train=False, transform=trans, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_index(class_num, dataset, mode:str):\n",
    "    if mode == 'train':\n",
    "        class_indx = torch.nonzero(\n",
    "                dataset.train_labels == class_num * torch.ones_like(dataset.train_labels)\n",
    "        )\n",
    "\n",
    "    if mode == 'test':\n",
    "        class_indx = torch.nonzero(\n",
    "                dataset.test_labels == class_num * torch.ones_like(dataset.test_labels)\n",
    "        )\n",
    "\n",
    "    class_indx = class_indx.squeeze(1)\n",
    "    return class_indx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(get_index(8, train_data, 'train'))\n",
    "test_sampler = SubsetRandomSampler(get_index(8, test_data, 'test'))\n",
    "\n",
    "train_loader=DataLoader(train_data, batch_size= batch_size, sampler=train_sampler)\n",
    "test_loader=DataLoader(test_data, batch_size= batch_size, sampler=test_sampler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = Generator(img_size=img_size, latent_dim=latent_dim, channels=channels).cuda()\n",
    "discriminator = Discriminator(channels=channels, img_size=img_size).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters())\n",
    "optimizer_D = optim.Adam(discriminator.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = generator.apply(weights_init_normal)\n",
    "discriminator = discriminator.apply(weights_init_normal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs):\n",
    "    total_G_loss = 0.0\n",
    "    total_D_loss = 0.0\n",
    "    for i, (real_images, _) in enumerate(train_loader):\n",
    "        valid = torch.FloatTensor(real_images.shape[0], 1).fill_(1.0).cuda()\n",
    "        fake = torch.FloatTensor(real_images.shape[0], 1).fill_(0.0).cuda()\n",
    "        real_images = real_images.cuda()\n",
    "\n",
    "        #  Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.FloatTensor(np.random.normal(0, 1, (real_images.shape[0], latent_dim))).cuda()\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        total_G_loss += g_loss.cpu().detach().numpy()\n",
    "\n",
    "        #  Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        discriminator_opinion_real = discriminator(real_images)\n",
    "        discriminator_opinion_fake = discriminator(gen_imgs.detach())\n",
    "        real_loss = adversarial_loss(discriminator_opinion_real, valid)\n",
    "        fake_loss = adversarial_loss(discriminator_opinion_fake, fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        total_D_loss += d_loss.cpu().detach().numpy()\n",
    "\n",
    "    if epoch % sample_interval ==0:\n",
    "\n",
    "        # show a sample from generator\n",
    "        z = torch.FloatTensor(np.random.normal(0, 1, (real_images.shape[0], latent_dim))).cuda()\n",
    "        gen_imgs = generator(z)\n",
    "        show_tensor_images(gen_imgs)\n",
    "        show_tensor_images(real_images)\n",
    "\n",
    "\n",
    "\n",
    "        # show losses\n",
    "        print(\n",
    "                \"[Epoch {}/{}] \\t[D loss: {:.3f}] \\t[G loss: {:.3f}]\".format(\n",
    "                    epoch, num_epochs, total_D_loss, total_G_loss)\n",
    "            )\n",
    "\n",
    "        # save all\n",
    "        torch.save({\"epoch\": epoch,\n",
    "            \"state_dict_G\": generator.state_dict(),\n",
    "            \"state_dict_D\": discriminator.state_dict(),\n",
    "            \"optimizer_G\": optimizer_G.state_dict(),\n",
    "            \"optimizer_D\": optimizer_D.state_dict()\n",
    "           }, root_save + f\"/epoch{epoch}_disloss{total_D_loss}_genloss{total_G_loss}.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if epoch % sample_interval == 0 and i % (len(dataloader)/5) == 0:\n",
    "    save_image(gen_imgs.data[0,0],\n",
    "               \"images/{}_{}.png\".format(str(epoch).zfill(len(str(num_epochs))),\n",
    "                                         str(i).zfill(len(str(len(dataloader))))),\n",
    "               normalize=True)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### End"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}